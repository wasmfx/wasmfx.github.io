<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
    <title>Explainer document | WasmFX: Effect Handlers for WebAssembly</title>
    <link rel="stylesheet" type="text/css" href="/wasmfx.css">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
  </head>
  <body>
    <header class="page-section">
      <div class="container-narrow">
        <a class="site-logo" href="/"></a>
        <h2>Effect Handlers for WebAssembly</h2>
        <nav class="site-nav">
          <a class="site-nav-item btn" href="/">Overview</a>
          <a class="site-nav-item btn" href="/specs">Specs</a>
          <a class="site-nav-item btn" href="/community">Community</a>
        </nav>
      </div>
    </header>
    <section>
      <div class="container">
        <div class="row">
          <div class="col-xs-12 col-lg-9 col-pop">
            <h1 id="typed-continuations">Typed continuations</h1>
            <p>This document provides an informal presentation of
        the <i>typed continuations</i> proposal, a minimal and
        compatible extension to Wasm for structured non-local control
        flow. The proposal is minimal in the sense that it leverages
        Wasm's existing instruction set and type system. It extends
        the instruction set with instructions to suspend, resume, and
        abort computations, and extends the type system with a single
        new reference type for
        <i>continuations</i>.</p>

<h2 id="motivation">Motivation</h2>
            <p>
              Non-local control flow features provide the ability to
suspend the current execution context and later resume it. Many
industrial-strength programming languages feature a wealth of
non-local control flow features such as async/await, coroutines,
generators/iterators, effect handlers, call/cc, and so forth. For some
programming languages non-local control flow is central to their
identity, meaning that they rely on non-local control flow for
efficiency, e.g. to support massively scalable concurrency.
            </p>

<p>Currently, Wasm lacks support for implementing such features directly
and efficiently without a circuitous global transformation of source
programs on the producer side. One possible strategy is to add special
support for each individual non-local control flow feature to Wasm,
but strategy does not scale to the next 700 non-local control flow
features. Instead, the goal of this proposal is to introduce a unifed
structured mechanism that is sufficiently general to cover present
use-cases as well as being forwards compatible with future use-cases,
  while admitting efficient implementations.
  </p>

<p>
The proposed mechanism is based on proven technology: <i>delimited
continuations</i>. An undelimited continuation represents the rest of a
computation from a certain point in its execution. A delimited
continuation is a more modular form of continuation, representing the
rest of a computation from a particular point in its execution up to a
<i>delimiter</i> or <i>prompt</i>. Operationally, one may think of
undelimited continuations as stacks and delimited continuations as
segmented stacks.
</p>

<p>
In their raw form delimited continuations do not readily fit into the
Wasm ecosystem, as the Wasm type system is not powerful enough to type
them. The gist of the problem is that the classic treatment of
delimited continuations provides only one universal control tag
(i.e. the mechanism which transforms a runtime stack into a
programmatic data object). In order to use Wasm's simple type system
to type delimited continuations, we use the idea of multiple <i>named</i>
control tags from Plotkin and Pretnar's effect handlers. Each control
tag is declared module-wide along its payload type and return
type. This declaration can be used to readily type points of non-local
transfer of control. From an operational perspective we may view
control tags as a means for writing an interface for the possible
kinds of non-local transfers (or stack switches) that a computation
may perform.
</p>

<h3 id="typed-continuation-primer">Typed continuation primer</h3>

<p>
A <i>continuation</i> is a first-class program object that represents the
remainder of computation from a certain point in the execution of a
program &mdash; intuitively, its current stack. The typed continuations
proposal is based on a structured notion of delimited continuations. A
<i>delimited continuation</i> is a continuation whose extent is
delimited by some <i>control delimiter</i>, meaning it represents the
remainder of computation from a certain point up to (and possibly
including) its control delimiter -- intuitively, a segment of the
stack. An alternative to delimited continuations is undelimited
continuations which represent the remainder of the <i>entire</i>
program. Delimited continuations are preferable as they are more
modular and more fine-grained in the sense that they provide a means
for suspending local execution contexts rather than the entire global
execution context. In particular, delimited continuations are more
expressive, as an undelimited continuation is merely a delimited
continuation whose control delimiter is placed at the start of the
program.
</p>

            <p> The crucial feature of the typed continuations
proposal that makes it more structured than conventional delimited
continuations is <i>control tags</i>. A control tag is a typed
symbolic entity that suspends the current execution context and
reifies it as a <i>continuation object</i> (henceforth,
just <i>continuation</i>) up to its control delimiter. The type of a
control tag communicates the type of its payload as well as its
expected return type, i.e. the type of data that must be supplied to
its associated continuation upon resumption. In other words, control
tags define an <i>interface</i> for constructing continuations.
            </p>


            <p>
              A second aspect of the design that aids modularity by separating
concerns is that the construction of continuations is distinct from
<i>handling</i> of continuations. A continuation is handled at the
delimiter of a control tag rather than at the invocation site of the
control tag. Control tags are a mild extension of exception tags as in
the exception handling proposal. The key difference is that in
addition to a payload type, a control tag also declares a return
type. Roughly, control tags can be thought of as resumable exceptions.
</p>

            <p>
Typed continuations may be efficiently implemented using segmented
stacks, but other implementations are also possible.
            </p>

<h2 id="additional-requirements">Additional requirements</h2>

<ul>
  <li><b>No GC dependency</b>: We intend every language to be able to
   use typed continuations to implement non-local flow abstractions
   irrespective of whether its memory is managed by a GC. Thus this
   proposal must not depend on the presence of a full-blown GC as in
   the GC proposal, rather, reference counting or a similar technique
   must be sufficient in cases where some form of memory management is
   necessary.
  </li>
   <li><b>Debugging friendliness</b>: The addition of continuations
   must preserve compatibility with standard debugging formats such as
   DWARF, meaning it must be possible to obtain a sequential
   unobstructed stack trace in the presence of continuations.
  </li>
  <li><b>Exception handling compatibility</b>: <a href="https://github.com/WebAssembly/exception-handling">The
   exception handling proposal</a> adds special support for one kind
   of non-local control flow abstraction, namely, exception
   handlers. Exceptions must continue to work in the presence of typed
   continuations and vice versa.
  </li>
  <li><b>Preserve Wasm invariants of legacy code</b>: The proposal must
   provide a means to protect the invariants of existing Wasm
   code. For instance, this means that in the presence of code that
   uses typed continuations it should be possible to ensure that other
   legacy code cannot suspend. The mechanism for protecting invariants
   need not be automatic (in the same vein as explicit synchronisation
   might be needed when adding threads and shared memory).
  </li>

<h2 id="instruction-set">Instruction set</h2>

<p>
  The proposal adds a new reference type for continuations.
</p>

<pre>
  <code>
    (cont $t)
  </code>
</pre>

<p>
A continuation type is given in terms of a function
type <code>$t</code>, whose parameters <code>tp*</code> describes the
expected stack shape prior to resuming/starting the continuation, and
whose return types <code>tr*</code> describes the stack shape after
the continuation has run to completion.
</p>

<p>
As a shorthand, we will often write the function type inline and write
a continuation type as
</p>

<pre>
  <code>
  (cont [tp*] -> [tr*])
  </code>
</pre>

<h3 id="declaring-control-tags">Declaring control tags</h3>

<p>
A control tag is similar to an exception extended with a result type
(or list thereof). Operationally, a control tag may be thought of as a
<i>resumable</i> exception. A tag declaration provides the type signature
of a control tag.
</p>

<pre>
  <code>
  (tag $e (param tp*) (result tr*))
  </code>
</pre>

<p>
The <code>$e</code> is the symbolic index of the control tag in the
index space of tags. The parameter types <code>tp*</code> describe the
expected stack layout prior to invoking the tag, and the result
types <code>tr*</code> describe the stack layout following an
invocation of the operation. In this document we will sometimes
write <code>$e : [tp*] -> [tr*]</code> as shorthand for indicating
that such a declaration is in scope.
</p>

<h3 id="creating-continuations">Creating continuations</h3>

<p>
The following instruction creates a continuation in <i>suspended state</i>
from a function.
</p>

<pre>
  <code>
  cont.new $ct : [(ref $ft)] -> [(ref $ct)]
  where:
  - $ft = func [t1*] -> [t2*]
  - $ct = cont $ft
  </code>
</pre>

<p>
The instruction takes as operand a reference to
a function of type <code>[t1*] -> [t2*]</code>. The body of this function is a
computation that may perform non-local control flow.
</p>

<h3 id="invoking-continuations">Invoking continuations</h3>

<p>
  There are two ways to invoke (or run) a continuation.
</p>

<p>
The first way to invoke a continuation resumes the continuation under
a <i>handler</i>, which handles subsequent control suspensions within the
continuation.
</p>

<pre>
  <code>
  resume (tag $e $l)* : [tp* (ref $ct)] -> [tr*]
  where:
  - $ct = cont [tp*] -> [tr*]
  </code>
</pre>

<p>
The <code>resume</code> instruction is parameterised by a handler defined by a
collection of pairs of control tags and labels. Each pair maps a
control tag to a label pointing to its corresponding handler code. The
<code>resume</code> instruction consumes its continuation argument, meaning a
continuation may be resumed only once.
</p>

<p>
The second way to invoke a continuation is to raise an exception at
the control tag invocation site. This amounts to performing "an
abortive action" which causes the stack to be unwound.
</p>

<pre>
  <code>
  resume_throw $exn : [tp* (ref $ct)])] -> [tr*]
  where:
  - $ct = cont [ta*] -> [tr*]
  - $exn : [tp*] -> []
  </code>
</pre>

<p>
The instruction <code>resume_throw</code> is parameterised by the exception to be
raised at the control tag invocation site. As with <code>resume</code>, this
instruction also fully consumes its continuation
argument. Operationally, this instruction raises the exception <code>$exn</code>
with parameters of type <code>tp*</code> at the control tag invocation point in
the context of the supplied continuation. As an exception is being
raised (the continuation is not actually being supplied a value) the
parameter types for the continuation <code>ta*</code> are unconstrained.
</p>

<h3 id="suspending-continuations">Suspending continuations</h3>

<p>
A computation running inside a continuation can suspend itself by
invoking one of the declared control tags.
</p>

<pre>
  <code>
  suspend $e : [tp*] -> [tr*]
  where:
  - $e : [tp*] -> [tr*]
  </code>
</pre>

<p>
The instruction <code>suspend</code> invokes the control tag named <code>$e</code> with
arguments of types <code>tp*</code>. Operationally, the instruction transfers
control out of the continuation to the nearest enclosing handler for
<code>$e</code>. This behaviour is similar to how raising an exception
transfers control to the nearest exception handler that handles the
exception. The key difference is that the continuation at the
suspension point expects to be resumed later with arguments of types
<code>tr*</code>.
</p>

<h3 id="binding-continuations">Binding continuations</h3>

<p>
The parameter list of a continuation may be shrunk via <code>cont.bind</code>. This
instruction provides a way to partially apply a given
continuation. This facility turns out to be important in practice due
to the block and type structure of Wasm as in order to return a
continuation from a block, all branches within the block must agree on
the type of continuation. By using <code>cont.bind</code>, one can
programmatically ensure that the branches within a block each return a
continuation with compatible type (the <a href="#examples">Examples</a> section
provides several example usages of <code>cont.bind</code>).
</p>

<pre>
  <code>
  cont.bind $ct2 : [tp1* (ref $ct1)] -> [(ref $ct2)]
  where:
  $ct1 = cont [tp1* tp2*] -> [tr*]
  $ct2 = cont [tp2*] -> [tr*]
  </code>
</pre>

<p>
The instruction <code>cont.bind</code> binds the arguments of type <code>tp1*</code> to a
continuation of type <code>$ct1</code>, yielding a modified continuation of type
<code>$ct2</code> which expects fewer arguments. This instruction also
consumes its continuation argument, and yields a new continuation that
can be supplied to
either <code>resume</code>,<code>resume_throw</code>,
or <code>cont.bind</code>.
</p>

<h3 id="trapping-continuations">Trapping continuations</h3>

<p>
In order to allow ensuring that control cannot be captured across
certain abstraction or language boundaries, we provide an instruction
for explicitly trapping attempts at reifying stacks across a certain
point.
</p>

<pre>
  <code>
  barrier $l bt instr* end : [t1*] -> [t2*]
  where:
  - bt = [t1*] -> [t2*]
  - instr* : [t1*] -> [t2*]
  </code>
</pre>

<p>
The <code>barrier</code> instruction is a block with
label <code>$l</code>, block type
<code>bt = [t1*] -> [t2*]</code>, whose body is the instruction
sequence given
by <code>instr*</code>. Operationally, <code>barrier</code> may be
viewed as a "catch-all" handler, that handles any control tag by
invoking a trap.
</p>

<h2 id="continuation-lifetime">Continuation lifetime</h2>

<h3 id="producing-continuations">Producing continuations</h3>

<p>
There are three different ways in which continuations are produced
(<code>cont.new,suspend,cont.bind</code>). A fresh continuation object is
allocated with <code>cont.new</code> and the current continuation is reused with
`suspend` and <code>cont.bind</code>.
</p>

<p>
The <code>cont.bind</code> instruction is directly analogous to the mildly
controversial <code>func.bind</code> instruction from the function references
proposal. However, whereas the latter necessitates the allocation of a
new closure, as continuations are single-shot no allocation is
necessary: all allocation happens when the original continuation is
created by preallocating one slot for each continuation argument.
</p>

<h3 id="consuming-continuations">Consuming continuations</h3>

<p>
There are three different ways in which continuations are consumed
(<code>resume,resume_throw,cont.bind</code>). A continuation is
resumed with a particular handler with <code>resume</code>. A continuation is
aborted with <code>resume_throw</code>. A continuation is partially
applied with <code>cont.bind</code>.
</p>

<p>
In order to ensure that continuations are one-shot, <code>resume</code>,
<code>resume_throw</code>, and <code>cont.bind</code> destructively
modify the continuation object such that any subsequent use of the
same continuation object will result in a trap.
</p>

<h2 id="examples">Examples</h2>

<h3 id="lightweight-threads-static">Lightweight threads (static)</h3>

<p>
(The full code for this example
is <a href="https://github.com/effect-handlers/wasm-spec/tree/master/proposals/continuations/examples/static-lwt.wast">here</a>.)
</p>

<p>
Lightweight threads are one of the primary use-cases for typed
continuations. In their most basic <i>static</i> form we assume a fixed
collection of cooperative threads with a single tag that allows a
thread to signal that it is willing to yield.
</p>

<pre>
  <code>
(module $lwt
  (tag $yield (export "yield"))
)
(register "lwt")
  </code>
</pre>

<p>
The <code>$yield</code> tag takes no parameter and has no
result. Having declared it, we can now write some cooperative threads
as functions.
</p>

<pre>
  <code>
(module $example
  (tag $yield (import "lwt" "yield"))
  (func $log (import "spectest" "print_i32") (param i32))

  (func $thread1 (export "thread1")
    (call $log (i32.const 10))
    (suspend $yield)
    (call $log (i32.const 11))
    (suspend $yield)
    (call $log (i32.const 12))
  )

  (func $thread2 (export "thread2")
    (call $log (i32.const 20))
    (suspend $yield)
    (call $log (i32.const 21))
    (suspend $yield)
    (call $log (i32.const 22))
  )

  (func $thread3 (export "thread3")
    (call $log (i32.const 30))
    (suspend $yield)
    (call $log (i32.const 31))
    (suspend $yield)
    (call $log (i32.const 32))
  )
)
(register "example")
  </code>
</pre>

<p>
Our intention is to interleave the execution of <code>$thread1</code>,
<code>$thread2</code>, and <code>$thread3</code>, using <code>(suspend
$yield)</code> to suspend execution to a scheduler which will perform
a context switch.
</p>

<p>
If we were to try to run any of these functions at the top-level then
they would trap as soon as they try to suspend with
the <code>$yield</code> tag, because we have not yet specified how to
handle it.
</p>

<p>
  We now define a scheduler.
</p>

<pre>
  <code>
(module $scheduler
  (type $func (func))
  (type $cont (cont $func))

  (tag $yield (import "lwt" "yield"))

  ;; queue interface
  (func $queue-empty (import "queue" "queue-empty") (result i32))
  (func $dequeue (import "queue" "dequeue") (result (ref null $cont)))
  (func $enqueue (import "queue" "enqueue") (param $k (ref $cont)))

  (func $run (export "run")
    (loop $l
      (if (call $queue-empty) (then (return)))
      (block $on_yield (result (ref $cont))
        (resume (tag $yield $on_yield)
                (call $dequeue)
        )
        (br $l)  ;; thread terminated
      ) ;;   $on_yield (result (ref $cont))
      (call $enqueue)  ;; continuation of current thread
      (br $l)
    )
  )
)
(register "scheduler")
  </code>
</pre>

<p>
We assume a suitable interface to a queue of active threads
represented as continuations. The scheduler is a loop which repeatedly
runs the continuation (thread) at the head of the queue. It does so by
resuming the continuation with a handler for the `$yield` tag. The
handler <code>(tag $yield $on_yield)</code> specifies that the <code>$yield</code> tag
is handled by running the code immediately following the block
labelled with <code>$on_yield</code>, the <code>$on_yield</code> clause. The result of the
block <code>(result (ref $cont))</code> declares that there will be a
continuation on the stack when suspending with the <code>$yield</code> tag,
which is the continuation of the currently executing thread. The
<code>$on_yield</code> clause enqueues this continuation and proceeds
to the next iteration of the loop.
</p>

<p>
In order to interleave our three test threads together, we create a
new continuation for each, enqueue the continuations, and invoke the
scheduler. The <code>cont.new</code> operation turns a function
reference into a corresponding continuation reference.
</p>

<pre>
  <code>
(module
  (type $func (func))
  (type $cont (cont $func))

  (func $scheduler (import "scheduler" "run"))
  (func $enqueue (import "queue" "enqueue") (param (ref $cont)))

  (func $log (import "spectest" "print_i32") (param i32))

  (func $thread1 (import "example" "thread1"))
  (func $thread2 (import "example" "thread2"))
  (func $thread3 (import "example" "thread3"))

  (elem declare func $thread1 $thread2 $thread3)

  (func (export "run")
    (call $enqueue (cont.new (type $cont) (ref.func $thread1)))
    (call $enqueue (cont.new (type $cont) (ref.func $thread2)))
    (call $enqueue (cont.new (type $cont) (ref.func $thread3)))

    (call $log (i32.const -1))
    (call $scheduler)
    (call $log (i32.const -2))
  )
)

(invoke "run")
  </code>
</pre>

  <p>
    The output is as follows.
  </p>

<pre>
  <code>
-1 : i32
10 : i32
20 : i32
30 : i32
11 : i32
21 : i32
31 : i32
12 : i32
22 : i32
32 : i32
-2 : i32
  </code>
</pre>

  <p>
    The threads are interleaved as expected.
  </p>

<h3 id="lightweight-threads-dynamic">Lightweight threads (dynamic)</h3>

<p>
(The full code for this example
is <a href="https://github.com/effect-handlers/wasm-spec/tree/master/proposals/continuations/examples/lwt.wast">here</a>.)
</p>

<p>
We can make our lightweight threads functionality considerably more
expressive by allowing new threads to be forked dynamically.
</p>

<pre>
  <code>
(module $lwt
  (type $func (func))
  (type $cont (cont $func))

  (tag $yield (export "yield"))
  (tag $fork (export "fork") (param (ref $cont)))
)
(register "lwt")
  </code>
</pre>

<p>
We declare a new <code>$fork</code> tag that takes a continuation as a
parameter and (like <code>$yield</code>) returns no result. Now we
modify our example to fork each of the three threads from a single
main thread.
</p>

<pre>
  <code>
(module $example
  (type $func (func))
  (type $cont (cont $func))

  (tag $yield (import "lwt" "yield"))
  (tag $fork (import "lwt" "fork") (param (ref $cont)))

  (func $log (import "spectest" "print_i32") (param i32))

  (elem declare func $thread1 $thread2 $thread3)

  (func $main (export "main")
    (call $log (i32.const 0))
    (suspend $fork (cont.new (type $cont) (ref.func $thread1)))
    (call $log (i32.const 1))
    (suspend $fork (cont.new (type $cont) (ref.func $thread2)))
    (call $log (i32.const 2))
    (suspend $fork (cont.new (type $cont) (ref.func $thread3)))
    (call $log (i32.const 3))
  )

  (func $thread1
    (call $log (i32.const 10))
    (suspend $yield)
    (call $log (i32.const 11))
    (suspend $yield)
    (call $log (i32.const 12))
  )

  (func $thread2
    (call $log (i32.const 20))
    (suspend $yield)
    (call $log (i32.const 21))
    (suspend $yield)
    (call $log (i32.const 22))
  )

  (func $thread3
    (call $log (i32.const 30))
    (suspend $yield)
    (call $log (i32.const 31))
    (suspend $yield)
    (call $log (i32.const 32))
  )
)
(register "example")
  </code>
</pre>

<p>
  As with the static example we define a scheduler module.
</p>
<pre>
  <code>
(module $scheduler
  (type $func (func))
  (type $cont (cont $func))

  (tag $yield (import "lwt" "yield"))
  (tag $fork (import "lwt" "fork") (param (ref $cont)))

  (func $queue-empty (import "queue" "queue-empty") (result i32))
  (func $dequeue (import "queue" "dequeue") (result (ref null $cont)))
  (func $enqueue (import "queue" "enqueue") (param $k (ref null $cont)))
  ...
)
(register "scheduler")
  </code>
</pre>

<p>
In this example we illustrate five different schedulers. First, we
write a baseline synchronous scheduler which simply runs the current
thread to completion without actually yielding.
</p>

<pre>
  <code>
  (func $sync (export "sync") (param $nextk (ref null $cont))
    (loop $l
      (if (ref.is_null (local.get $nextk)) (then (return)))
      (block $on_yield (result (ref $cont))
        (block $on_fork (result (ref $cont) (ref $cont))
          (resume (tag $yield $on_yield)
                  (tag $fork $on_fork)
                  (local.get $nextk)
          )
          (local.set $nextk (call $dequeue))
          (br $l)  ;; thread terminated
        ) ;;   $on_fork (result (ref $cont) (ref $cont))
        (local.set $nextk)                      ;; current thread
        (call $enqueue) ;; new thread
        (br $l)
      )
      ;;     $on_yield (result (ref $cont))
      (local.set $nextk)  ;; carry on with current thread
      (br $l)
    )
  )
  </code>
</pre>

<p>
The <code>$nextk</code> parameter represents the continuation of the
next thread. The loop is repeatedly executed until <code>$nextk</code>
is null (meaning that all threads have finished). The body of the loop
is the code inside the two nested blocks. It resumes the next
continuation, dequeues the next continuation, and then continues to
the next iteration of the loop. The handler passed
to <code>resume</code> specifies how to handle
both <code>$yield</code> and <code>$fork</code> tags. Yielding carries
on executing the current thread (this scheduler is
synchronous). Forking enqueues the new thread and continues executing
the current thread.
</p>

<p>
As with the static example, the result of the <code>$on_yield</code> block
<code>(result (ref $cont))</code> declares that there will be a continuation on
the stack when suspending with the <code>$yield</code> tag, which is the
continuation of the currently executing thread. The result of the
<code>$on_fork</code> block <code>(result (ref $cont) (ref
$cont))</code> declares that there will be two continuations on the
stack when suspending with the
<code>$fork</code> tag: the first is the parameter passed to fork (the
new thread) and the second is the continuation of the currently
executing thread.
</p>

<p>
  Running the synchronous scheduler on the example produces the following output.
</p>
<pre>
  <code>
0 : i32
1 : i32
2 : i32
3 : i32
10 : i32
11 : i32
12 : i32
20 : i32
21 : i32
22 : i32
30 : i32
31 : i32
32 : i32
  </code>
</pre>
<p>
First the main thread runs to completion, then each of the forked
threads in sequence.
</p>

<p>
Following a similar pattern, we define four different asynchronous
schedulers.
</p>

<pre>
  <code>
  ;; four asynchronous schedulers:
  ;;   * kt and tk don't yield on encountering a fork
  ;;     1) kt runs the continuation, queuing up the new thread for later
  ;;     2) tk runs the new thread first, queuing up the continuation for later
  ;;   * ykt and ytk do yield on encountering a fork
  ;;     3) ykt runs the continuation, queuing up the new thread for later
  ;;     4) ytk runs the new thread first, queuing up the continuation for later

  ;; no yield on fork, continuation first
  (func $kt (export "kt") (param $nextk (ref null $cont))
    (loop $l
      (if (ref.is_null (local.get $nextk)) (then (return)))
      (block $on_yield (result (ref $cont))
        (block $on_fork (result (ref $cont) (ref $cont))
          (resume (tag $yield $on_yield)
                  (tag $fork $on_fork)
                  (local.get $nextk)
          )
          (local.set $nextk (call $dequeue))
          (br $l)  ;; thread terminated
        ) ;;   $on_fork (result (ref $cont) (ref $cont))
        (local.set $nextk)                      ;; current thread
        (call $enqueue) ;; new thread
        (br $l)
      )
      ;;     $on_yield (result (ref $cont))
      (call $enqueue)                    ;; current thread
      (local.set $nextk (call $dequeue)) ;; next thread
      (br $l)
    )
  )

  ;; no yield on fork, new thread first
  (func $tk (export "tk") (param $nextk (ref null $cont))
    (loop $l
      (if (ref.is_null (local.get $nextk)) (then (return)))
      (block $on_yield (result (ref $cont))
        (block $on_fork (result (ref $cont) (ref $cont))
          (resume (tag $yield $on_yield)
                  (tag $fork $on_fork)
                  (local.get $nextk)
          )
          (local.set $nextk (call $dequeue))
          (br $l)  ;; thread terminated
        ) ;;   $on_fork (result (ref $cont) (ref $cont))
        (call $enqueue)                            ;; current thread
        (local.set $nextk) ;; new thread
        (br $l)
      )
      ;;     $on_yield (result (ref $cont))
      (call $enqueue)                    ;; current thread
      (local.set $nextk (call $dequeue)) ;; next thread
      (br $l)
    )
  )

  ;; yield on fork, continuation first
  (func $ykt (export "ykt") (param $nextk (ref null $cont))
    (loop $l
      (if (ref.is_null (local.get $nextk)) (then (return)))
      (block $on_yield (result (ref $cont))
        (block $on_fork (result (ref $cont) (ref $cont))
          (resume (tag $yield $on_yield)
                  (tag $fork $on_fork)
                  (local.get $nextk)
          )
          (local.set $nextk (call $dequeue))
          (br $l)  ;; thread terminated
        ) ;;   $on_fork (result (ref $cont) (ref $cont))
        (call $enqueue)                         ;; current thread
        (call $enqueue) ;; new thread
        (local.set $nextk (call $dequeue))      ;; next thread
        (br $l)
      )
      ;;     $on_yield (result (ref $cont))
      (call $enqueue)                    ;; current thread
      (local.set $nextk (call $dequeue)) ;; next thread
      (br $l)
    )
  )

  ;; yield on fork, new thread first
  (func $ytk (export "ytk") (param $nextk (ref null $cont))
    (loop $l
      (if (ref.is_null (local.get $nextk)) (then (return)))
      (block $on_yield (result (ref $cont))
        (block $on_fork (result (ref $cont) (ref $cont))
          (resume (tag $yield $on_yield)
                  (tag $fork $on_fork)
                  (local.get $nextk)
          )
          (local.set $nextk (call $dequeue))
          (br $l)  ;; thread terminated
        ) ;;   $on_fork (result (ref $cont) (ref $cont))
        (local.set $nextk)
        (call $enqueue) ;; new thread
        (call $enqueue (local.get $nextk))      ;; current thread
        (local.set $nextk (call $dequeue))      ;; next thread
        (br $l)
      )
      ;;     $on_yield (result (ref $cont))
      (call $enqueue)                    ;; current thread
      (local.set $nextk (call $dequeue)) ;; next thread
      (br $l)
    )
  )
  </code>
</pre>

<p>
Each <code>$on_yield</code> clause is identical, enqueing the continuation of the
current thread and dequeing the next continuation for the thread. The
<code>$on_fork</code> clauses implement different behaviours for scheduling the
current and newly forked threads.
</p>

<p>
We run our example using each of the five schedulers.
</p>

<pre>
  <code>
(module
  (type $func (func))
  (type $cont (cont $func))

  (func $scheduler1 (import "scheduler" "sync") (param $nextk (ref null $cont)))
  (func $scheduler2 (import "scheduler" "kt") (param $nextk (ref null $cont)))
  (func $scheduler3 (import "scheduler" "tk") (param $nextk (ref null $cont)))
  (func $scheduler4 (import "scheduler" "ykt") (param $nextk (ref null $cont)))
  (func $scheduler5 (import "scheduler" "ytk") (param $nextk (ref null $cont)))

  (func $log (import "spectest" "print_i32") (param i32))

  (func $main (import "example" "main"))

  (elem declare func $main)

  (func (export "run")
    (call $log (i32.const -1))
    (call $scheduler1 (cont.new (type $cont) (ref.func $main)))
    (call $log (i32.const -2))
    (call $scheduler2 (cont.new (type $cont) (ref.func $main)))
    (call $log (i32.const -3))
    (call $scheduler3 (cont.new (type $cont) (ref.func $main)))
    (call $log (i32.const -4))
    (call $scheduler4 (cont.new (type $cont) (ref.func $main)))
    (call $log (i32.const -5))
    (call $scheduler5 (cont.new (type $cont) (ref.func $main)))
    (call $log (i32.const -6))
  )
)

(invoke "run")
  </code>
</pre>

<p>
The output is as follows, demonstrating the various different scheduling behaviours.
</p>

<pre>
  <code>
-1 : i32
0 : i32
1 : i32
2 : i32
3 : i32
10 : i32
11 : i32
12 : i32
20 : i32
21 : i32
22 : i32
30 : i32
31 : i32
32 : i32
-2 : i32
0 : i32
1 : i32
2 : i32
3 : i32
10 : i32
20 : i32
30 : i32
11 : i32
21 : i32
31 : i32
12 : i32
22 : i32
32 : i32
-3 : i32
0 : i32
10 : i32
1 : i32
20 : i32
11 : i32
2 : i32
30 : i32
21 : i32
12 : i32
3 : i32
31 : i32
22 : i32
32 : i32
-4 : i32
0 : i32
1 : i32
10 : i32
2 : i32
20 : i32
11 : i32
3 : i32
30 : i32
21 : i32
12 : i32
31 : i32
22 : i32
32 : i32
-5 : i32
0 : i32
10 : i32
1 : i32
11 : i32
20 : i32
2 : i32
12 : i32
21 : i32
30 : i32
3 : i32
22 : i32
31 : i32
32 : i32
-6 : i32
  </code>
</pre>

<h3 id="delimited-continuations">Delimited continuations</h3>

<p>
(The full code for this example
is <a href="https://github.com/effect-handlers/wasm-spec/tree/master/proposals/continuations/examples/control-lwt.wast">here</a>.)
</p>

<p>
Conventional unstructured delimited continuations can be directly
implemented using our typed continuations design. Here we illustrate
how to implement lightweight threads on top of the control/prompt
delimited control operators.
</p>

<p>
First we implement control/prompt.
</p>

<pre>
  <code>
;; interface to control/prompt
(module $control
  (type $func (func))       ;; [] -> []
  (type $cont (cont $func)) ;; cont ([] -> [])

  ;; we sometimes write contref as shorthand for a reference to a continuation

  (type $cont-func (func (param (ref $cont)))) ;; [contref ([] -> [])] -> []
  (type $cont-cont (cont $cont-func))          ;; cont ([contref ([] -> [])] -> [])

  ;; Implementation of a generic delimited control operator using
  ;; effect handlers.
  ;;
  ;; For lightweight threads we have no payload. More general types
  ;; for control and prompt are:
  ;;
  ;;   control : [([contref ([ta*] -> [tr*])] -> [tr*])] -> [ta*]
  ;;   prompt : [contref ([] -> [tr*])] -> [tr*]
  ;;
  ;; (We can also give more refined types if we want to support
  ;; answer-type modification and various flavours of answer-type
  ;; polymorphism - but these are well outside the scope of a Wasm
  ;; proposal!)
  ;;
  ;; (Technically this is control0/prompt0 rather than
  ;; control/prompt.)
  (tag $control (export "control") (param (ref $cont-func)))    ;; control : [([contref ([] -> [])] -> [])] -> []
  (func $prompt (export "prompt") (param $nextk (ref null $cont)) ;; prompt : [(contref ([] -> []))] -> []
    (block $on_control (result (ref $cont-func) (ref $cont))
       (resume (tag $control $on_control)
               (local.get $nextk))
       (return)
    ) ;;   $on_control (param (ref $cont-func) (ref $cont))
    (let (local $h (ref $cont-func)) (local $k (ref $cont))
      (call_ref (local.get $k) (local.get $h))
    )
  )
)
(register "control")
  </code>
</pre>

<p>
The <code>$control</code> tag amounts to a universal control tag,
which takes a second-order function <code>$h</code> as an argument
(it's second-order in that it's a function that itself takes a
function, wrapped in a continuation, as an argument). The
implementation of prompt is the universal handler
for <code>$control</code>, which simply applies the second order
function <code>$h</code> to the captured continuation.
</p>

<p>
In the above code we have specialised <code>$control</code>
and <code>$prompt</code> to the case where the continuation has no
parameters and no results, as this suffices for implementing
lightweight threads. A continuation parameter corresponds to the
result of a control tag, so in the absence of parametric polymorphism,
in order to simulate standard control tags in general we would need
one copy of <code>$control</code> for each type of result we wanted to
support.
</p>

<p>
The following example is just like the one we implemented for dynamic
lightweight threads using <code>$yield</code> and <code>$fork</code>
tags decoupled from handlers for defining different schedulers. Here
instead we parameterise the whole example by the behaviour of yielding
and forking as <code>$yield</code> and <code>$fork</code> functions.
</p>

<pre>
  <code>
(module $example
  (type $func (func))       ;; [] -> []
  (type $cont (cont $func)) ;; cont ([] -> [])

  (type $cont-func (func (param (ref $cont)))) ;; [cont ([] -> [])] -> []
  (type $cont-cont (cont $cont-func))          ;; cont ([cont ([] -> [])] -> [])

  (type $func-cont-func-func (func (param (ref $func)) (param (ref $cont-func)))) ;; ([] -> []) -> ([contref ([] -> [])] -> []) -> []
  (type $func-cont-func-cont (cont $func-cont-func-func))                         ;; cont (([] -> []) -> ([contref ([] -> [])] -> []) -> [])

  (func $log (import "spectest" "print_i32") (param i32))

  (elem declare func $main $thread1 $thread2 $thread3)

  (func $main (export "main") (param $yield (ref $func)) (param $fork (ref $cont-func))
    (call $log (i32.const 0))
    (call_ref
      (cont.bind (type $cont) (local.get $yield) (local.get $fork)
        (cont.new (type $func-cont-func-cont) (ref.func $thread1)))
      (local.get $fork))
    (call $log (i32.const 1))
    (call_ref
      (cont.bind (type $cont) (local.get $yield) (local.get $fork)
        (cont.new (type $func-cont-func-cont) (ref.func $thread2)))
      (local.get $fork))
    (call $log (i32.const 2))
    (call_ref
      (cont.bind (type $cont) (local.get $yield) (local.get $fork)
        (cont.new (type $func-cont-func-cont) (ref.func $thread3)))
      (local.get $fork))
    (call $log (i32.const 3))
  )

  (func $thread1 (param $yield (ref $func)) (param $fork (ref $cont-func))
    (call $log (i32.const 10))
    (call_ref (local.get $yield))
    (call $log (i32.const 11))
    (call_ref (local.get $yield))
    (call $log (i32.const 12))
  )

  (func $thread2 (param $yield (ref $func)) (param $fork (ref $cont-func))
    (call $log (i32.const 20))
    (call_ref (local.get $yield))
    (call $log (i32.const 21))
    (call_ref (local.get $yield))
    (call $log (i32.const 22))
  )

  (func $thread3 (param $yield (ref $func)) (param $fork (ref $cont-func))
    (call $log (i32.const 30))
    (call_ref (local.get $yield))
    (call $log (i32.const 31))
    (call_ref (local.get $yield))
    (call $log (i32.const 32))
  )
)
(register "example")
  </code>
</pre>

<p>
The function type <code>$func-cont-func-fun</code> is the type of a
function that takes an implementation of a <code>$yield</code>
function and the implementation as a <code>$fork</code> function as
pararameters; the continuation type
<code>$func-cont-func-cont</code> is the same thing as a continuation.
</p>

<p>
We now define a scheduler module analogous to that of the previous
dynamic lightweight thread example. As before, we will implement five
different schedulers.
</p>

<pre>
  <code>
(module
  (type $func (func))       ;; [] -> []
  (type $cont (cont $func)) ;; cont ([] -> [])

  (type $cont-func (func (param (ref $cont)))) ;; [contref ([] -> [])] -> []
  (type $cont-cont (cont $cont-func))          ;; [(contref ([contref ([] -> [])]))] -> []

  (type $func-cont-func-func (func (param (ref $func)) (param (ref $cont-func)))) ;; ([] -> []) -> ([cont ([] -> [])] -> []) -> []
  (type $func-cont-func-cont (cont $func-cont-func-func))                         ;; cont (([] -> []) -> ([cont ([] -> [])] -> []) -> [])

  (elem declare func
     $handle-yield-sync $handle-yield
     $handle-fork-sync $handle-fork-kt $handle-fork-tk $handle-fork-ykt $handle-fork-ytk
     $yield
     $fork-sync $fork-kt $fork-tk $fork-ykt $fork-ytk)

  ;; control/prompt interface
  (tag $control (import "control" "control") (param (ref $cont-func)))     ;; control : ([cont ([] -> [])] -> []) -> []
  (func $prompt (import "control" "prompt") (param $nextk (ref null $cont))) ;; prompt : cont ([] -> []) -> []

  ;; queue interface
  (func $queue-empty (import "queue" "queue-empty") (result i32))
  (func $dequeue (import "queue" "dequeue") (result (ref null $cont)))
  (func $enqueue (import "queue" "enqueue") (param $k (ref $cont)))
  ...
(register "scheduler")
  </code>
</pre>

<p>
Unlike before, with control/prompt a generic scheduler loop must be
decoupled from the implementations of each operation (yield / fork) as
the latter are passed in as arguments to user code
</p>

<pre>
  <code>
  ;; generic boilerplate scheduler
  (func $scheduler (param $nextk (ref null $cont))
    (loop $loop
      (if (ref.is_null (local.get $nextk)) (then (return)))
      (call $prompt (local.get $nextk))
      (local.set $nextk (call $dequeue))
      (br $loop)
    )
  )
  </code>
</pre>

<p>
The scheduler loop simply keeps on calling prompt with the next thread
in the queue until the queue of threads is exhausted.
</p>

<p>
For each scheduler, we invoke the generic scheduler using a
continuation parameterised by suitable implementations of yield and
fork.
</p>

<p>
First, we do the baseline synchronous scheduler.
</p>

<pre>
  <code>
  ;; synchronous scheduler
  (func $handle-yield-sync (param $k (ref $cont))
    (call $scheduler (local.get $k))
  )
  (func $yield-sync
    (suspend $control (ref.func $handle-yield))
  )
  (func $handle-fork-sync (param $t (ref $cont)) (param $k (ref $cont))
    (call $enqueue (local.get $t))
    (call $scheduler (local.get $k))
  )
  (func $fork-sync (param $t (ref $cont))
    (suspend $control (func.bind (type $cont-func) (local.get $t) (ref.func $handle-fork-sync)))
  )
  (func $sync (export "sync") (param $k (ref $func-cont-func-cont))
    (call $scheduler
      (cont.bind (type $cont) (ref.func $yield) (ref.func $fork-sync) (local.get $k)))
  )
  </code>
</pre>

<p>
The <code>func.bind</code> instruction is needed in the
implementations of fork More generally <code>func.bind</code> is
needed for any operation that takes arguments. One could use another
continuation here instead, but constructing a new continuation every
time an operation is invoked seems unnecessarily wasteful.
</p>

<p>
All of the asynchronous schedulers make use of the same implementation
of yield, which enqueues the continuation of the current thread and
dequeues the next available thread.
</p>

<pre>
  <code>
  ;; asynchronous yield (used by all asynchronous schedulers)
  (func $handle-yield (param $k (ref $cont))
    (call $enqueue (local.get $k))
    (call $scheduler (call $dequeue))
  )
  (func $yield
    (suspend $control (ref.func $handle-yield))
  )
  </code>
</pre>

<p>
Each asynchronous scheduler uses its own implementation of fork.
</p>

<pre>
  <code>
  ;; four asynchronous implementations of fork:
  ;;   * kt and tk don't yield on encountering a fork
  ;;     1) kt runs the continuation, queuing up the new thread for later
  ;;     2) tk runs the new thread first, queuing up the continuation for later
  ;;   * ykt and ytk do yield on encountering a fork
  ;;     3) ykt runs the continuation, queuing up the new thread for later
  ;;     4) ytk runs the new thread first, queuing up the continuation for later

  ;; no yield on fork, continuation first
  (func $handle-fork-kt (param $t (ref $cont)) (param $k (ref $cont))
    (call $enqueue (local.get $t))
    (call $scheduler (local.get $k))
  )
  (func $fork-kt (param $t (ref $cont))
    (suspend $control (func.bind (type $cont-func) (local.get $t) (ref.func $handle-fork-kt)))
  )
  (func $kt (export "kt") (param $k (ref $func-cont-func-cont))
    (call $scheduler
      (cont.bind (type $cont) (ref.func $yield) (ref.func $fork-kt) (local.get $k)))
  )

  ;; no yield on fork, new thread first
  (func $handle-fork-tk (param $t (ref $cont)) (param $k (ref $cont))
    (call $enqueue (local.get $k))
    (call $scheduler (local.get $t))
  )
  (func $fork-tk (param $t (ref $cont))
    (suspend $control (func.bind (type $cont-func) (local.get $t) (ref.func $handle-fork-tk)))
  )
  (func $tk (export "tk") (param $k (ref $func-cont-func-cont))
    (call $scheduler
      (cont.bind (type $cont) (ref.func $yield) (ref.func $fork-tk) (local.get $k)))
  )

  ;; yield on fork, continuation first
  (func $handle-fork-ykt (param $t (ref $cont)) (param $k (ref $cont))
    (call $enqueue (local.get $k))
    (call $enqueue (local.get $t))
    (call $scheduler (call $dequeue))
  )
  (func $fork-ykt (param $t (ref $cont))
    (suspend $control (func.bind (type $cont-func) (local.get $t) (ref.func $handle-fork-ykt)))
  )
  (func $ykt (export "ykt") (param $k (ref $func-cont-func-cont))
    (call $scheduler
      (cont.bind (type $cont) (ref.func $yield) (ref.func $fork-ykt) (local.get $k)))
  )

  ;; yield on fork, new thread first
  (func $handle-fork-ytk (param $t (ref $cont)) (param $k (ref $cont))
    (call $enqueue (local.get $t))
    (call $enqueue (local.get $k))
    (call $scheduler (call $dequeue))
  )
  (func $fork-ytk (param $t (ref $cont))
    (suspend $control (func.bind (type $cont-func) (local.get $t) (ref.func $handle-fork-ytk)))
  )
  (func $ytk (export "ytk") (param $k (ref $func-cont-func-cont))
    (call $scheduler
      (cont.bind (type $cont) (ref.func $yield) (ref.func $fork-ytk) (local.get $k)))
  )
)
(register "scheduler")
  </code>
</pre>

<p>
Invoking the schedulers is much like in our original dynamic
lightweight threads example, but the types are more complex due to the
need to index the handled computation (`$main` in this case) by the
implementations of forking and yielding.
</p>

<pre>
  <code>
(module
  (type $func (func))       ;; [] -> []
  (type $cont (cont $func)) ;; cont ([] -> [])

  (type $cont-func (func (param (ref $cont)))) ;; [contref ([] -> [])] -> []
  (type $cont-cont (cont $cont-func))          ;; cont ([contref ([] -> [])] -> [])

  (type $func-cont-func-func (func (param (ref $func)) (param (ref $cont-func)))) ;; ([] -> []) -> ([contref ([] -> [])] -> []) -> []
  (type $func-cont-func-cont (cont $func-cont-func-func))                         ;; contref (([] -> []) -> ([contref ([] -> [])] -> []) -> [])

  (func $scheduler-sync (import "scheduler" "sync") (param $nextk (ref $func-cont-func-cont)))
  (func $scheduler-kt (import "scheduler" "kt") (param $nextk (ref $func-cont-func-cont)))
  (func $scheduler-tk (import "scheduler" "tk") (param $nextk (ref $func-cont-func-cont)))
  (func $scheduler-ykt (import "scheduler" "ykt") (param $nextk (ref $func-cont-func-cont)))
  (func $scheduler-ytk (import "scheduler" "ytk") (param $nextk (ref $func-cont-func-cont)))

  (func $log (import "spectest" "print_i32") (param i32))

  (func $main (import "example" "main") (param $yield (ref $func)) (param $fork (ref $cont-func)))

  (elem declare func $main)

  (func $run (export "run")
    (call $log (i32.const -1))
    (call $scheduler-sync (cont.new (type $func-cont-func-cont) (ref.func $main)))
    (call $log (i32.const -2))
    (call $scheduler-kt (cont.new (type $func-cont-func-cont) (ref.func $main)))
    (call $log (i32.const -3))
    (call $scheduler-tk (cont.new (type $func-cont-func-cont) (ref.func $main)))
    (call $log (i32.const -4))
    (call $scheduler-ykt (cont.new (type $func-cont-func-cont) (ref.func $main)))
    (call $log (i32.const -5))
    (call $scheduler-ytk (cont.new (type $func-cont-func-cont) (ref.func $main)))
    (call $log (i32.const -6))
  )
)
  </code>
</pre>

<p>
The output of running this code is just as in the direct
implementation of dynamic lightweight threads.
</p>

<h2 id="design-considerations-and-extensions">Design considerations and extensions</h2>

<h3 id="memory-management">Memory management</h3>

<p>
The current proposal does not require a general garbage collector as
the linearity of continuations guarantees that there are no cycles in
continuation objects. In theory, we could dispense with automated
memory management altogether if we took seriously the idea that
failure to use a continuation constitutes a bug in the producer. In
practice, for most producers enforcing such a discipline is
unrealistic and not something an engine can rely on anyway. To prevent
space leaks, most engines will need some form of automated memory
meanagement for unconsumed continuations. Due to the acyclicity of
continuations, a reference counting scheme is sufficient.
</p>

<h3 id="linear-versus-constant-time-dispatch">Linear versus constant time dispatch</h3>

<p>
The <code>suspend</code> instruction relies on traversing a stack of
handlers in order to find the appropriate handler, similarly to
exception handling. A potential problem is that this can incur a
linear runtime cost, especially if we think in terms of segmented
stacks, where <code>suspend</code> must search the active stack chain
for a suitable handler for its argument. Practical experience from
Multicore OCaml suggests that for critical use cases (async/await,
lightweight threads, actors, etc.) the depth of the handler stack
tends to be small so the cost of this linear traversal is
negligible. Nonetheless, future applications may benefit from
constant-time dispatch. To enable constant-time dispatch we would need
to know the target stack a priori, which might be acheived either by
maintaining a shadow stack or by extending <code>suspend</code> to
explicitly target a named handler.
</p>

<h3 id="named-handlers">Named handlers</h3>

<p>
We can accommodate named handlers by introducing a new reference type
<code>handler t*</code>, which essentially is a unique prompt created
by executing a variant of the `resume` instruction and is passed to
the continuation:
</p>

<pre>
  <code>
  resume_with (tag $e $l)* : [ t1* (ref $ht) ] -> [ t2* ]
  where:
  - $ht = handler t2*
  - $ct = cont ([ (ref $ht) t1* ] -> [ t2* ])
  </code>
</pre>

<p>
The handler reference is similar to a prompt in a system of
multi-prompt continuations. However, since it is created fresh for
each handler, multiple activations of the same prompt cannot exist by
construction.
</p>

<p>
This instruction is complemented by an instruction for suspending to a
specific handler:
</p>

<pre>
  <code>
  suspend_to $e : [ s* (ref $ht) ] -> [ t* ]
  where:
  - $ht = handler tr*
  - $e : [ s* ] -> [ t* ]
  </code>
</pre>

<p>
If the handler is not currently active, e.g., because an outer handler
has been suspended, then this instruction would trap.
<p>

<h3 id="direct-switching">Direct switching</h3>

<p>
The current proposal uses the asymmetric suspend/resume pair of
primitives that is characteristic of effect handlers. It does not
include a symmetric way of switching to another continuation directly,
without going through a handler, and it is conceivable that the double
hop through a handler might involve unnecessary overhead for use cases
like lightweight threading.
<p>

<p>
Though there is currently no evidence that the double hop overhead is
significant in practice, if it does turn out to be important for some
applications then the current proposal can be extended with a more
symmetric `switch_to` primitive.
</p>

<p>
Given named handlers, it is possible to introduce a somewhat magic
instruction for switching directly to another continuation:
</p>

<pre>
  <code>
  switch_to : [ t1* (ref $ct1) (ref $ht) ] -> [ t2* ]
  where:
  - $ht = handler t3*
  - $ct1 = cont ([ (ref $ht) (ref $ct2$) t1* ] -> [ t3* ])
  - $ct2 = cont ([ t2* ] -> [ t3* ])
  </code>
</pre>

<p>
This behaves as if there was a built-in tag
</p>

<pre>
  <code>
  (tag $Switch (param t1* (ref $ct1)) (result t3*))
  </code>
</pre>

<p>
with which the computation suspends to the handler, and the handler
implicitly handles this by resuming to the continuation argument,
thereby effectively switching to it in one step. Like <code>suspend_to</code>,
this would trap if the handler was not currently active.
</p>

<p>
The fact that the handler implicitly resumes, passing itself as a
handler to the target continuation, makes this construct behave like a
deep handler, which is slightly at odds with the rest of the proposal.
</p>

<p>
In addition to the handler, <code>switch_to</code> also passes the new
continuation to the target, which allows the target to switch back to
it in a symmetric fashion. Notably, in such a use case, <code>$ct1</code> and
<code>$ct2</code> would be the same type (and hence recursive).
</p>

<p>
In fact, symmetric switching need not necessarily be tied to named
handlers, since there could also be an indirect version with dynamic
handler lookup:
</p>

<pre>
  <code>
  switch : [ t1* (ref $ct1) ] -> [ t2* ]
  where:
  - $ct1 = cont ([ (ref $ct2) t1* ] -> [ t3* ])
  - $ct2 = cont ([ t2* ] -> [ t3* ])
  </code>
</pre>

<p>
It seems undesirable that every handler implicitly handles the
built-in <code>$Switch</code> tag, so this should be opt-in by a mode flag on the
resume instruction(s).
</p>

<h3 id="controlprompt-as-an-alternative-basis">Control/prompt as an alternative basis</h3>

<p>
An alternative to our typed continuations proposal is to use more
established delimited control operators such as control/prompt and
shift/reset. As illustrated in the examples section, control/prompt
can be viewed as a special instance of the current proposal with a
single universal control tag <code>control</code> and a handler for each
<code>prompt</code>.
</p>

<p>
As <code>control</code> amounts to a universal control tag it
correspondingly has a higher-order type. As illustrated by the
example, this requires more complicated types than with the current
proposal and depends on greater use of function closures.
</p>

<p>
When considered as a source language feature effect handlers are
preferable to control/prompt because they are more modular and easier
to reason about. Effect handlers naturally provide a separation of
concerns. Users program to an effect interface,
whereas <code>control</code> allows (and indeed requires) them to
essentially rewrite the implementation inline (in practice this is
unmanageable, so one abstracts over a few key behaviours using
functions as illustrated in the example). Of course, intermediate
languages have different requirements to source languages, so
modularity and ease of reasoning may be less critical. Nonetheless,
they should not be discounted entirely.
</p>

<h3 id="coupling-of-continuation-capture-and-dispatch">Coupling of continuation capture and dispatch</h3>

<p>
A possible concern with the current design is that it relies on a
specific form of dispatch based on tags. Suspending not only captures
the current continuation up to the nearest prompt, but also dispatches
to the handler clause associated with the given tag. It might be
tempting to try to decouple continuation capture from dispatch, but it
is unclear what other form of dispatch would be useful or whether
there is a clean way to enable such decoupling.
</p>

<p>
With control/prompt there is no coupling of continuation capture with
dispatch, because there is no dispatch. But this is precisely because
<code>control</code> behaves as a universal tag, which requires
behaviour to be given inline via a closure, breaking modularity and
necessitating a higher-order type even for simple uses of
continuations like lightweight threads.
</p>

<p>
This is not to say that control/prompt or a generalisation to
multiprompt delimited continuations is necessarily a bad low-level
implementation technique. For instance, the
<a href="https://github.com/koka-lang/libmprompt">libmprompt</a> C
library implements effect handlers on top of multiprompt delimited
continuations. However, a key difference there is that the C
implementation does not require static stack typing, something that is
fundamental to the design of Wasm. Thus, the implementation does not
need to contend directly with the higher-order type of <code>control</code>.
</p>

<h3 id="tail-resumptive-handlers">Tail-resumptive handlers</h3>

<p>
A handler is said to be <i>tail-resumptive</i> if the handler invokes
the continuation in tail-position in every control tag clause. The
canonical example of a tail-resumptive handler is dynamic binding
(which can be useful to implement implicit parameters to
computations). The control tag clauses of a tail-resumptive handler
can be inlined at the control tag invocation sites, because they do
not perform any non-trivial control flow manipulation, they simply
retrieve a value. Inlining clause definitions means that no time is
spent constructing continuation objects.
</p>

<p>
The present iteration of this proposal does not include facilities for
identifying and inlining tail-resumptive handlers. None of the
critical use-cases requires such a facility. Nevertheless, it is
natural to envisage a future iteration of this proposal that includes
an extension for distinguishing tail-resumptive handlers.
</p>

<h3 id="multi-shot-continuations">Multi-shot continuations</h3>

<p>
Continuations in this proposal are <i>single-shot</i>
(aka <i>linear</i>), meaning that they must be invoked exactly once
(though this is not statically enforced). A continuation can be
invoked either by resuming it (with <code>resume</code>) or by
aborting it (with <code>resume_throw</code>). Some applications such
as backtracking, probabilistic programming, and process duplication
exploit <i>multi-shot</i> continuations, but none of the critical use
cases require multi-shot continuations. Nevertheless, it is natural to
envisage a future iteration of this proposal that includes support for
multi-shot continuations by way of a continuation clone instruction.
</p>

<h3 id="interoperability-legacy-code-and-the-barrier-instruction">Interoperability, legacy code, and the barrier instruction</h3>

<p>
The barrier instruction provides a direct way of preventing control
tags from being suspended outside a particular computation.
</p>

<p>
Consider a module A written using an existing C/C++ compiler that
targets a Wasm backend. Let us assume that module A depends on a
second Wasm module B. Now suppose that the producer for module B is
updated to take advantage of typed continuations. In order to ensure
that suspensions arising in calls to B do not pass through A,
potentially causing unexpected changes to the semantics of A, the
producer for module A can ensure that all external calls are wrapped
in the barrier instruction.
</p>

<p>
It might seem preferable to somehow guarantee that support for typed
continuations is not enabled by default, meaning that no changes to
the producer for module A would be necessary. But it is unclear what
such an approach would look like in practice and whether it would
actually be feasible. In any case, using the barrier instruction the
producer for B could make module B safe for linking with an unchanged
module A by wrapping the barrier instruction around all of the
functions exported by module B.
</p>

<p>
Questions of Wasm interoperability and support for legacy code are
largely orthogonal to the typed continuations proposal and similar
issues already arise with extensions such as exceptions.
</p>

<h3 id="first-class-tags">First-class tags</h3>

<p>
In the current proposal tags are statically defined in a module
header. This should suffice for supporting the critical
use-cases. However, for some purposes, such as implementing richer
forms of control operators such as effect handlers, it might be useful
to add support for dynamically generated tags. These could be used,
for instance, for more efficiently compiling effect handlers that take
advantage of features such as Multicore OCaml's functors, where the
type of an effect (tag) may not be fully known at compile time.
</p>

<h3 id="shallow-versus-deep-handlers">Shallow versus deep handlers</h3>

<p>
The effect handlers feature which underlies the design of the typed
continuations proposal classically comes in too forms: shallow and
deep handlers. With shallow handlers, the installation of handlers is
completely decoupled from resuming a continuation. With deep handlers,
the handler that produced the continuation is automatically
reinstalled when a continuation is resumed. The typed continuations
proposal adopts a hybrid of shallow and deep handlers, which we call
<i>sheep handlers</i>. Like a shallow handler, there is no automatic
reinstallation of an existing handler. But like deep handlers a new
handler is installed when a continuation is resumed: the new handler
is written explicitly as part of the `resume` instruction.
</p>
</div>
          <div class="col-xs-12 col-lg-3">
            <h6 class="side-title">Table of contents</h6>
            <nav class="side-nav">
              <a class="side-nav-item" href="#motivation">Motivation</a>
              <ul>
                <li><a class="side-nav-item" href="#typed-continuation-primer">Typed continuation primer</a></li>
              </ul>
              <a class="side-nav-item" href="#additional-requirements">Additional requirements</a>
              <a class="side-nav-item" href="#instruction-set">Instruction set</a>
              <ul>
                <li><a class="side-nav-item" href="#declaring-control-tags">Declaring control tags</a></li>
                <li><a class="side-nav-item" href="#creating-continuations">Creating continuations</a></li>
                <li><a class="side-nav-item" href="#invoking-continuations">Invoking continuations</a></li>
                <li><a class="side-nav-item" href="#suspending-continuations">Suspending continuations</a></li>
                <li><a class="side-nav-item" href="#binding-continuations">Binding continuations</a></li>
                <li><a class="side-nav-item" href="#trapping-continuations">Trapping continuations</a></li>
              </ul>
              <a class="side-nav-item" href="#continuation-lifetime">Continuation lifetime</a>
              <ul>
                <li><a class="side-nav-item" href="#producing-continuations">Producing continuations</a></li>
                <li><a class="side-nav-item" href="#consuming-continuations">Consuming continuations</a></li>
              </ul>
              <a class="side-nav-item" href="#examples">Examples</a>
              <ul>
                <li><a class="side-nav-item" href="#lightweight-threads-static">Lightweight threads (static)</a></li>
                <li><a class="side-nav-item" href="#lightweight-threads-dynamic">Lightweight threads (dynamic)</a></li>
                <li><a class="side-nav-item" href="#delimited-continuations">Delimited continuations</a></li>
              </ul>
              <a class="side-nav-item" href="#design-considerations-and-extensions">Design considerations and extensions</a>
              <ul>
                <li><a class="side-nav-item" href="#memory-management">Memory management</a></li>
                <li><a class="side-nav-item" href="#linear-versus-constant-time-dispatch">Linear versus constant time dispatch</a></li>
                <li><a class="side-nav-item" href="#named-handlers">Named handlers</a></li>
                <li><a class="side-nav-item" href="#direct-switching">Direct switching</a></li>
                <li><a class="side-nav-item" href="#controlprompt-as-an-alternative-basis">Control/prompt as an alternative basis</a></li>
                <li><a class="side-nav-item" href="#coupling-of-continuation-capture-and-dispatch">Coupling of continuation capture and dispatch</a></li>
                <li><a class="side-nav-item" href="#tail-resumptive-handlers">Tail-resumptive handlers</a></li>
                <li><a class="side-nav-item" href="#multi-shot-continuations">Multi-shot continuations</a></li>
                <li><a class="side-nav-item" href="#interoperability-legacy-code-and-the-barrier-instruction">Interoperability, legacy code, and the barrier instruction</a></li>
                <li><a class="side-nav-item" href="#first-class-tags">First-class tags</a></li>
                <li><a class="side-nav-item" href="#shallow-versus-deep-handlers">Shallow versus deep handlers</a></li>
              </ul>
            </nav>
          </div>
        </div>
    </section>
  </body>
</html>
